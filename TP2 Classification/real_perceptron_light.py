# -*- coding: utf-8 -*-
"""Real Perceptron light.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SMuEj3E5jMk2e-Kh6LqMUDplfacfnUXy
"""

import numpy as np
import random

"""

1.   Génération du dataset


"""

#Fonction de création des points 
def random_numbers(size,bmin,bmax):
  exist = set()
  points = []
  i = 0
  while i<size:
    x = random.uniform(bmin,bmax)
    y = random.uniform(-1,1) 
    if (x,y) not in exist:
      if x>0:
        points.append([x,y,1])
      else:
        points.append([x,y,0])

      exist.add((x,y))
      i+=1
  return points

input = random_numbers(50,-1,1)
input[0]

"""2.   Création et training de notre modèle de perceptron
Ici nous allons créer notre classe " Perceptron " qui contiendra deux fonctions:


*   La fonction "predict" qui effectuera du coup les prédictions en utilisant les paramètres données
*   La fonction "train_weights" qui se chargera de paramètrer les weights selon les résultats des prédictions.

N.B : Le premier élément du tableau weights représentera notre biais 




"""

class Perceptron():
  def __init__(self,nb_weight):
    self.nb_weight = nb_weight
    

  # On utilise les poids pour la p
  def predict(self,row, weights):
    activation = weights[0]
    for i in range(len(row)-1):
      activation += weights[i + 1] * row[i]
    return 1.0 if activation >= 0.0 else 0.0
  
  """Voici la fonction qui nous permettra d'evaluer nos weights en utilisant
     La descente de gradient stochastic
     
      """
  def train_weights(self,dataset, l_rate, n_epoch):
    #Le premier element de la liste représentera le biais
  	weights = [random.random() for i in range(self.nb_weight)]
  	for epoch in range(n_epoch):
  		sum_error = 0.0
  		for row in dataset:
  			prediction = predict(row, weights)
  			error = row[-1] - prediction
  			sum_error += error**2
  			weights[0] = weights[0] + l_rate * error
  			for i in range(len(row)-1):
  				weights[i + 1] = weights[i + 1] + l_rate * error * row[i]
  		print('>epoch=%d, lrate=%.3f, error=%.3f' % (epoch, l_rate, sum_error))
  	return weights

model = Perceptron(3)
model.train_weights(input,0.1,20) # Learning rate = 0.1 / Nb_epochs = 20

